from typing import Optional
import random
import argparse
import json
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed


from obh.utils import load_objects, setup_llm_client, rate_limited_call
from obh.utils.prompts import PROMPTGEN_SYS_PROMPT, QWEN_T2I_SYS_PROMPT, MAGIC_PROMPT_EN

def add_common_llm_args(parser: argparse.ArgumentParser) -> None:
    parser.add_argument(
        "--rpm",
        type=int,
        default=60,
        help="Requests per minute limit (default: 60)",
    )
    parser.add_argument(
        "--model",
        type=str,
        default="openai/gpt-4o",
        help="LLM model to use (default: openai/gpt-4o)",
    )
    parser.add_argument(
        "--base-url",
        type=str,
        default="https://openrouter.ai/api/v1",
        help="Base URL for LLM API (default: OpenRouter)",
    )
    parser.add_argument(
        "--api-key",
        type=str,
        help="API key (default: from OPENROUTER_API_KEY env var)",
    )



def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Object Harvest Generator")
    subparsers = parser.add_subparsers(dest="task", help="Available tasks")

    # Prompt-gen subcommand
    prompt_parser = subparsers.add_parser("prompt-gen", help="Generate prompts using LLM")
    prompt_parser.add_argument(
        "--objects-file",
        type=str,
        help="Path to text file with objects (one per line, format: 'object — descriptor')",
    )
    prompt_parser.add_argument(
        "--objects-list",
        type=str,
        help="Comma-separated list of objects (format: 'object — descriptor')",
    )
    prompt_parser.add_argument(
        "--num-prompts",
        type=int,
        required=True,
        help="Number of prompts to generate",
    )
    prompt_parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="Output NDJSON file path",
    )
    prompt_parser.add_argument(
        "--min-objects",
        type=int,
        help="Minimum number of objects to randomly select per prompt (optional)",
    )
    prompt_parser.add_argument(
        "--max-objects",
        type=int,
        help="Maximum number of objects to randomly select per prompt (optional)",
    )
    add_common_llm_args(prompt_parser)

    # Image-gen subcommand (placeholder)
    image_parser = subparsers.add_parser("image-gen", help="Generate images (not implemented)")
    image_parser.add_argument("--input", type=str, help="Input NDJSON file")
    add_common_llm_args(image_parser)

    # Prompt-enhance subcommand
    enhance_parser = subparsers.add_parser("prompt-enhance", help="Enhance prompts using Qwen T2I prompt optimizer")
    enhance_parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="Input NDJSON file generated by prompt-gen",
    )
    enhance_parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="Output NDJSON file path",
    )
    add_common_llm_args(enhance_parser)

    return parser.parse_args()


def prompt_gen_task(args: argparse.Namespace) -> int:
    # Load objects
    objects = load_objects(args.objects_file, args.objects_list)
    if not objects:
        print("Error: No objects provided. Use --objects-file or --objects-list.")
        return 1

    # Validate min/max objects arguments
    if args.min_objects is not None or args.max_objects is not None:
        if args.min_objects is None or args.max_objects is None:
            print("Error: Both --min-objects and --max-objects must be specified together.")
            return 1
        if args.min_objects > args.max_objects:
            print("Error: --min-objects cannot be greater than --max-objects.")
            return 1
        if args.min_objects < 1 or args.max_objects < 1:
            print("Error: --min-objects and --max-objects must be at least 1.")
            return 1
        if args.max_objects > len(objects):
            print(f"Error: --max-objects cannot be greater than the number of available objects ({len(objects)}).")
            return 1

    # Setup LLM client
    client = setup_llm_client(args.base_url, args.api_key)

    # Rate limiting setup
    rpm = args.rpm
    interval = 60 / rpm  # seconds between requests

    def generate_prompt(i: int, objects: list[str], min_objects: Optional[int], max_objects: Optional[int]) -> str:
        if min_objects is not None and max_objects is not None:
            num = random.randint(min_objects, max_objects)
            selected_objects = random.sample(objects, num)
        else:
            selected_objects = objects
        objects_str = ", ".join(selected_objects)
        system_prompt = PROMPTGEN_SYS_PROMPT.format(objects=objects_str)
        return rate_limited_call(
            client,
            model=args.model,
            messages=[{"role": "system", "content": system_prompt}],
            interval=interval,
        )

    # Multi-threaded generation
    with ThreadPoolExecutor(max_workers=min(rpm, args.num_prompts)) as executor:
        futures = [executor.submit(generate_prompt, i, objects, args.min_objects, args.max_objects) for i in range(args.num_prompts)]
        results = []
        for future in tqdm(as_completed(futures), total=len(futures)):
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                print(f"Error in prompt generation: {e}")

    # Write to NDJSON
    with open(args.output, "w") as f:
        for result in results:
            f.write(result + "\n")

    print(f"Generated {len(results)} prompts to {args.output}")
    return 0


def image_gen_task(args: argparse.Namespace) -> int:
    raise NotImplementedError("Image generation not yet implemented")


def prompt_enhance_task(args: argparse.Namespace) -> int:
    # Setup LLM client
    client = setup_llm_client(args.base_url, args.api_key)

    # Rate limiting setup
    rpm = args.rpm
    interval = 60 / rpm  # seconds between requests

    # Read input NDJSON file
    input_data = []
    try:
        with open(args.input, "r") as f:
            for line in f:
                if line.strip():
                    input_data.append(json.loads(line.strip()))
    except FileNotFoundError:
        print(f"Error: Input file '{args.input}' not found.")
        return 1
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON in input file: {e}")
        return 1

    def enhance_prompt(entry: dict) -> dict:
        # Get the description to enhance
        description = entry.get("describe", "")
        
        # Call the LLM to enhance the prompt using QWEN_T2I_SYS_PROMPT as system prompt
        # and the description as the user input
        enhanced = rate_limited_call(
            client,
            model=args.model,
            messages=[
                {"role": "system", "content": QWEN_T2I_SYS_PROMPT},
                {"role": "user", "content": description + " " + MAGIC_PROMPT_EN},
            ],
            interval=interval,
        )
        
        # Create a new entry with the enhanced prompt
        new_entry = entry.copy()
        new_entry["prompt"] = enhanced
        return new_entry

    # Multi-threaded enhancement
    with ThreadPoolExecutor(max_workers=min(rpm, len(input_data))) as executor:
        futures = [executor.submit(enhance_prompt, entry) for entry in input_data]
        results = []
        for future in tqdm(as_completed(futures), total=len(futures)):
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                print(f"Error in prompt enhancement: {e}")

    # Write to output NDJSON file
    with open(args.output, "w") as f:
        for result in results:
            f.write(json.dumps(result) + "\\n")

    print(f"Enhanced {len(results)} prompts to {args.output}")
    return 0


def main() -> int:
    args = parse_args()
    if args.task == "prompt-gen":
        return prompt_gen_task(args)
    elif args.task == "image-gen":
        return image_gen_task(args)
    elif args.task == "prompt-enhance":
        return prompt_enhance_task(args)
    else:
        print("Error: No task specified. Use 'prompt-gen', 'image-gen', or 'prompt-enhance'.")
        return 1


if __name__ == "__main__":
    raise SystemExit(main())