import os
from typing import Optional, Dict, Any
import random
import argparse
import json
import uuid
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed


from obh.utils import load_objects, setup_llm_client, rate_limited_call
from obh.utils.prompts import PROMPTGEN_SYS_PROMPT, QWEN_T2I_SYS_PROMPT, MAGIC_PROMPT_EN
from obh.utils.validation import validate_and_clean_prompt_gen_response, restructure_objects
from obh.utils.qwen_image import QwenImage, ASPECT_RATIO_SIZES, MAX_SEED


def add_common_llm_args(parser: argparse.ArgumentParser) -> None:
    parser.add_argument(
        "--rpm",
        type=int,
        default=60,
        help="Requests per minute limit (default: 60)",
    )
    parser.add_argument(
        "--model",
        type=str,
        default="openai/gpt-4o",
        help="LLM model to use (default: openai/gpt-4o)",
    )
    parser.add_argument(
        "--base-url",
        type=str,
        default="https://openrouter.ai/api/v1",
        help="Base URL for LLM API (default: OpenRouter)",
    )
    parser.add_argument(
        "--api-key",
        type=str,
        help="API key (default: from OPENROUTER_API_KEY env var)",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=100,
        help="Batch size for processing (default: 100)",
    )



def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Object Harvest Generator")
    subparsers = parser.add_subparsers(dest="task", help="Available tasks")

    # Prompt-gen subcommand
    prompt_parser = subparsers.add_parser("prompt-gen", help="Generate prompts using LLM")
    prompt_parser.add_argument(
        "--objects-file",
        type=str,
        help="Path to text file with objects (one per line, format: 'object — descriptor')",
    )
    prompt_parser.add_argument(
        "--objects-list",
        type=str,
        help="Comma-separated list of objects (format: 'object — descriptor')",
    )
    prompt_parser.add_argument(
        "--num-prompts",
        type=int,
        required=True,
        help="Number of prompts to generate",
    )
    prompt_parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="Output NDJSON file path",
    )
    prompt_parser.add_argument(
        "--min-objects",
        type=int,
        help="Minimum number of objects to randomly select per prompt (optional)",
    )
    prompt_parser.add_argument(
        "--max-objects",
        type=int,
        help="Maximum number of objects to randomly select per prompt (optional)",
    )
    add_common_llm_args(prompt_parser)

    # Image-gen subcommand
    image_parser = subparsers.add_parser("image-gen", help="Generate images using Qwen-Image")
    image_parser.add_argument("--input", type=str, required=True, help="Input NDJSON file")
    image_parser.add_argument("--output", type=str, required=True, help="Output directory to save generated images and metadata")
    image_parser.add_argument("--model-path", type=str, default="Qwen/Qwen-Image", help="Hugging Face model path (default: Qwen/Qwen-Image)")
    image_parser.add_argument("--input-prompt-field", type=str, default="prompt", help="Field in input NDJSON to use as prompt (default: prompt)")
    image_parser.add_argument("--aspect-ratio", type=str, help="Aspect ratio from ASPECT_RATIO_SIZES (optional)")
    image_parser.add_argument("--num-inference-steps", type=int, default=8, help="Number of inference steps (default: 8)")
    image_parser.add_argument("--steps", type=int, default=8, help="Number of images to generate per prompt (default: 8)")
    image_parser.add_argument("--seed", type=int, default=0, help="Seed for reproducibility (default: 0)")
    image_parser.add_argument("--randomize-seed", action="store_false", dest="randomize_seed", default=True, help="Randomize seed (default: True). Use --randomize-seed to disable randomization.")
    image_parser.add_argument("--guidance-scale", type=float, default=1.0, help="Guidance scale (default: 1.0)")
    image_parser.add_argument("--format", type=str, choices=["png", "jpeg"], default="jpeg", help="Image format (default: jpeg)")

    # Prompt-enhance subcommand
    enhance_parser = subparsers.add_parser("prompt-enhance", help="Enhance prompts using Qwen T2I prompt optimizer")
    enhance_parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="Input NDJSON file generated by prompt-gen",
    )
    enhance_parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="Output NDJSON file path",
    )
    add_common_llm_args(enhance_parser)

    return parser.parse_args()


def prompt_gen_task(args: argparse.Namespace) -> int:
    # Load objects
    objects = load_objects(args.objects_file, args.objects_list)
    if not objects:
        print("Error: No objects provided. Use --objects-file or --objects-list.")
        return 1

    # Validate min/max objects arguments
    if args.min_objects is not None or args.max_objects is not None:
        if args.min_objects is None or args.max_objects is None:
            print("Error: Both --min-objects and --max-objects must be specified together.")
            return 1
        if args.min_objects > args.max_objects:
            print("Error: --min-objects cannot be greater than --max-objects.")
            return 1
        if args.min_objects < 1 or args.max_objects < 1:
            print("Error: --min-objects and --max-objects must be at least 1.")
            return 1
        if args.max_objects > len(objects):
            print(f"Error: --max-objects cannot be greater than the number of available objects ({len(objects)}).")
            return 1

    # Setup LLM client
    client = setup_llm_client(args.base_url, args.api_key)

    # Rate limiting setup
    rpm = args.rpm
    interval = 60 / rpm  # seconds between requests

    def generate_prompt(_: int, objects: list[str], min_objects: Optional[int], max_objects: Optional[int]) -> Dict[str, Any]:
        if min_objects is not None and max_objects is not None:
            num = random.randint(min_objects, max_objects)
            selected_objects = random.sample(objects, num)
        else:
            selected_objects = objects
        objects_str = ", ".join(selected_objects)
        system_prompt = PROMPTGEN_SYS_PROMPT.format(objects=objects_str)
        response = rate_limited_call(
            client,
            model=args.model,
            messages=[{"role": "system", "content": system_prompt}],
            interval=interval,
        )
        result = validate_and_clean_prompt_gen_response(response)
        result = restructure_objects(result)
        return result

    # Clear output file
    with open(args.output, "w") as f:
        pass

    batch_size = args.batch_size
    total_attempted = 0
    total_failed = 0
    total_successful = 0
    with ThreadPoolExecutor(max_workers=min(rpm, batch_size, os.cpu_count())) as executor:
        for start in range(0, args.num_prompts, batch_size):
            batch_end = min(start + batch_size, args.num_prompts)
            batch_indices = range(start, batch_end)
            futures = [executor.submit(generate_prompt, i, objects, args.min_objects, args.max_objects) for i in batch_indices]
            batch_results = []
            for future in tqdm(as_completed(futures), total=len(futures), desc=f"Batch {start//batch_size + 1}"):
                total_attempted += 1
                try:
                    result = future.result()
                    batch_results.append(result)
                    total_successful += 1
                except Exception as e:
                    print(f"Error in prompt generation: {e}")
                    total_failed += 1
            # Append batch results to file
            with open(args.output, "a") as f:
                for result in batch_results:
                    f.write(json.dumps(result) + "\n")

    print(f"Generated {total_successful} prompts to {args.output}")
    print("Prompt generation summary:")
    print(f"  Total attempted: {total_attempted}")
    print(f"  Successful: {total_successful}")
    print(f"  Failed: {total_failed}")
    return 0


def image_gen_task(args: argparse.Namespace) -> int:
    # Validate aspect_ratio if provided
    if args.aspect_ratio and args.aspect_ratio not in ASPECT_RATIO_SIZES:
        print(f"Error: Invalid aspect ratio '{args.aspect_ratio}'. Valid options: {list(ASPECT_RATIO_SIZES.keys())}")
        return 1

    # Create output directories
    images_dir = os.path.join(args.output, "images")
    os.makedirs(images_dir, exist_ok=True)

    # Initialize QwenImage
    generator = QwenImage(model_path=args.model_path)

    # Read input NDJSON
    input_data = []
    try:
        with open(args.input, "r") as f:
            for line in f:
                if line.strip():
                    input_data.append(json.loads(line.strip()))
    except FileNotFoundError:
        print(f"Error: Input file '{args.input}' not found.")
        return 1
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON in input file: {e}")
        return 1

    # Prepare metadata file
    metadata_path = os.path.join(args.output, "metadata.ndjson")
    with open(metadata_path, "w") as f:
        pass  # clear

    total_images = 0
    for idx, entry in enumerate(tqdm(input_data, desc="Processing prompts")):
        # Get prompt
        prompt = entry.get(args.input_prompt_field)
        if prompt is None:
            prompt = entry.get("describe")
        if prompt is None:
            print(f"Warning: No '{args.input_prompt_field}' or 'describe' field in entry {idx}, skipping.")
            continue

        # Generate steps images
        for step in range(args.steps):
            if args.randomize_seed:
                seed = random.randint(0, MAX_SEED)
            else:
                seed = args.seed + step  # vary per step for reproducibility

            # Generate image
            image = generator(
                prompt=prompt,
                aspect_ratio=args.aspect_ratio,
                num_inference_steps=args.num_inference_steps,
                seed=seed,
                randomize_seed=False,  # we handle seed here
                guidance_scale=args.guidance_scale,
            )

            # Generate uuid
            img_uuid = str(uuid.uuid4())

            # Filename
            filename = f"{idx}_{img_uuid}.{args.format}"

            img_path = os.path.join(images_dir, filename)

            # Save image
            image.save(img_path, args.format.upper())

            # Metadata entry
            meta_entry = {
                "image_path": f"images/{filename}",
            }
            if "prompt" in entry:
                meta_entry["prompt"] = entry["prompt"]
            if "description" in entry:
                meta_entry["description"] = entry["description"]
            if "objects" in entry:
                meta_entry["objects"] = entry["objects"]

            # Append to metadata
            with open(metadata_path, "a") as f:
                f.write(json.dumps(meta_entry) + "\n")

            total_images += 1

    print(f"Generated {total_images} images to {args.output}")
    return 0


def prompt_enhance_task(args: argparse.Namespace) -> int:
    # Setup LLM client
    client = setup_llm_client(args.base_url, args.api_key)

    # Rate limiting setup
    rpm = args.rpm
    interval = 60 / rpm  # seconds between requests

    # Read input NDJSON file
    input_data = []
    try:
        with open(args.input, "r") as f:
            for line in f:
                if line.strip():
                    input_data.append(json.loads(line.strip()))
    except FileNotFoundError:
        print(f"Error: Input file '{args.input}' not found.")
        return 1
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON in input file: {e}")
        return 1

    def enhance_prompt(entry: dict) -> dict:
        # Get the description to enhance
        description = entry.get("describe", "")
        
        # Call the LLM to enhance the prompt using QWEN_T2I_SYS_PROMPT as system prompt
        # and the description as the user input
        enhanced = rate_limited_call(
            client,
            model=args.model,
            messages=[
                {"role": "system", "content": QWEN_T2I_SYS_PROMPT},
                {"role": "user", "content": description + " " + MAGIC_PROMPT_EN},
            ],
            interval=interval,
        )
        
        # Create a new entry with the enhanced prompt
        new_entry = entry.copy()
        new_entry["prompt"] = enhanced
        return new_entry

    # Clear output file
    with open(args.output, "w") as f:
        pass

    batch_size = args.batch_size
    total_processed = 0
    with ThreadPoolExecutor(max_workers=min(rpm, batch_size, os.cpu_count())) as executor:
        for start in range(0, len(input_data), batch_size):
            batch = input_data[start:start + batch_size]
            futures = [executor.submit(enhance_prompt, entry) for entry in batch]
            batch_results = []
            for future in tqdm(as_completed(futures), total=len(futures), desc=f"Batch {start//batch_size + 1}"):
                try:
                    result = future.result()
                    batch_results.append(result)
                except Exception as e:
                    print(f"Error in prompt enhancement: {e}")
            # Append batch results to file
            with open(args.output, "a") as f:
                for result in batch_results:
                    f.write(json.dumps(result) + "\n")
            total_processed += len(batch_results)

    print(f"Enhanced {total_processed} prompts to {args.output}")
    return 0


def main() -> int:
    args = parse_args()
    if args.task == "prompt-gen":
        return prompt_gen_task(args)
    elif args.task == "image-gen":
        return image_gen_task(args)
    elif args.task == "prompt-enhance":
        return prompt_enhance_task(args)
    else:
        print("Error: No task specified. Use 'prompt-gen', 'image-gen', or 'prompt-enhance'.")
        return 1


if __name__ == "__main__":
    raise SystemExit(main())
