# Object Harvest

Object Harvest is a tool for generating and processing object-related data, including prompt generation using LLMs, image generation from prompts, and object detection in images.

## Features

- **Prompt Generation (`prompt-gen`)**: Generate scene descriptions containing specified objects using OpenAI-compatible LLMs (e.g., via OpenRouter).
- **Prompt Enhancement (`prompt-enhance`)**: Enhance prompts generated by `prompt-gen` using Qwen T2I prompt optimizer.
- **Image Generation (`image-gen`)**: Generate images from NDJSON prompts using Transformers diffusion models.
- **VLM Object Detection (`vlm`)**: Detect objects in images using Vision-Language Models (VLMs) with bounding boxes.
- **Multi-threading**: Efficient parallel processing with configurable rate limiting.
- **NDJSON Output**: Structured output for easy processing.

## Installation

1. Ensure you have Python ≥ 3.12 installed.
2. Clone the repository and navigate to the project directory.
3. Install dependencies using `uv`:

   ```bash
   uv venv
   uv pip install -e ."[all]"
   ```

## Setup

### API Keys
For LLM access, set your API key as an environment variable:

```bash
export OPENROUTER_API_KEY="your-api-key-here"
```

Or pass it via the `--api-key` CLI argument.

## Usage

### General Command Structure

For generation tasks:
```bash
uv run python -m obh.generate <task> [options]
```

Or using the installed script:
```bash
obh-generate <task> [options]
```

For detection tasks:
```bash
uv run python -m obh.detect <task> [options]
```

Or using the installed script:
```bash
obh-detect <task> [options]
```

### Tasks

#### Prompt Generation (`prompt-gen`)

Generates scene descriptions containing the specified objects using an LLM.

**Required Arguments:**
- `--num-prompts`: Number of prompts to generate
- `--output`: Path to output NDJSON file

**Object Input (choose one):**
- `--objects-file`: Text file with objects (one per line, format: `object — descriptor`)
- `--objects-list`: Comma-separated list (format: `object — descriptor`)

**Optional Arguments:**
- `--rpm`: Requests per minute limit (default: 60)
- `--model`: LLM model (default: `openai/gpt-4o`)
- `--base-url`: API base URL (default: `https://openrouter.ai/api/v1`)
- `--api-key`: API key (overrides env var)
- `--batch-size`: Batch size for processing (default: 100)
- `--min-objects`: Minimum number of objects to randomly select per prompt (must be used with `--max-objects`)
- `--max-objects`: Maximum number of objects to randomly select per prompt (must be used with `--min-objects`)

**Example:**

```bash
# Using objects list with random object selection
uv run python -m obh.generate prompt-gen \
  --objects-list "apple — red, shiny; banana — yellow, curved; orange — orange, round" \
  --num-prompts 5 \
  --min-objects 1 \
  --max-objects 2 \
  --output prompts.ndjson

# Using objects file with fixed batch size
echo "apple — red, shiny" > objects.txt
echo "banana — yellow, curved" >> objects.txt
echo "orange — orange, round" >> objects.txt
uv run python -m obh.generate prompt-gen \
  --objects-file objects.txt \
  --num-prompts 10 \
  --rpm 30 \
  --batch-size 50 \
  --output prompts.ndjson
```

**Output Format:**
Each line in the NDJSON file is a JSON object with:
- `describe`: The generated scene description
- `objects`: Array of objects with their exact phrasing in the description

**Processing Details:**
- Uses multi-threaded batch processing for efficient generation
- Displays progress bars for each batch
- Prints a summary of attempted, successful, and failed generations at the end

#### Image Generation (`image-gen`)

Generates images from NDJSON prompts using Transformers diffusion models.

**Required Arguments:**
- `--input`: Path to input NDJSON file
- `--output`: Output directory to save generated images and metadata

**Optional Arguments:**
- `--model-path`: Hugging Face model path (default: Qwen/Qwen-Image)
- `--input-prompt-field`: Field in input NDJSON to use as prompt (default: prompt)
- `--aspect-ratio`: Aspect ratio from ASPECT_RATIO_SIZES (optional)
- `--num-inference-steps`: Number of inference steps (default: 8)
- `--steps`: Number of images to generate per prompt (default: 1)
- `--seed`: Seed for reproducibility (default: 0)
- `--randomize-seed`: Randomize seed (default: True). Use --randomize-seed to disable randomization.
- `--guidance-scale`: Guidance scale (default: 1.0)
- `--format`: Image format (default: jpeg)

**Example:**

```bash
uv run python -m obh.generate image-gen \
  --input enhanced_prompts.ndjson \
  --output generated_images \
  --steps 2 \
  --aspect-ratio 1:1
```

**Output Format:**
Images are saved in the `images/` subdirectory of the output directory. A `metadata.ndjson` file is created with entries containing:
- `image_path`: Relative path to the generated image
- `prompt`: The prompt used (if available)
- `description`: The description (if available)
- `objects`: Array of objects (if available)

**Processing Details:**
- Processes each entry in the input NDJSON file
- Generates the specified number of images per prompt
- Uses UUIDs for unique filenames
- Displays progress bar during processing
- Prints total number of images generated

#### Prompt Enhancement (`prompt-enhance`)

Enhances prompts generated by `prompt-gen` using the Qwen T2I prompt optimizer to create more detailed and expressive prompts while preserving the original meaning.

**Required Arguments:**
- `--input`: Path to input NDJSON file generated by `prompt-gen`
- `--output`: Path to output NDJSON file

**Optional Arguments:**
- `--rpm`: Requests per minute limit (default: 60)
- `--model`: LLM model (default: `openai/gpt-4o`)
- `--base-url`: API base URL (default: `https://openrouter.ai/api/v1`)
- `--api-key`: API key (overrides env var)
- `--batch-size`: Batch size for processing (default: 100)

**Example:**

```bash
# Enhance prompts generated by prompt-gen
uv run python -m obh.generate prompt-enhance \
  --input prompts.ndjson \
  --output enhanced_prompts.ndjson \
  --rpm 30 \
  --batch-size 50
```

**Output Format:**
Each line in the NDJSON file is a JSON object with:
- `describe`: The original scene description from `prompt-gen`
- `objects`: Array of objects with their exact phrasing in the description
- `prompt`: The enhanced prompt generated by Qwen T2I prompt optimizer

**Processing Details:**
- Uses multi-threaded batch processing for efficient enhancement
- Displays progress bars for each batch
- Prints the total number of enhanced prompts at the end

### Detection Tasks

#### VLM Object Detection (`vlm`)

Detects objects in images using Vision-Language Models (VLMs) and outputs bounding boxes for each detected object.

**Required Arguments:**
- `--input`: Directory containing images (supports .jpg, .jpeg, .png)
- `--output`: Path to output JSONL file

**Optional Arguments:**
- `--rpm`: Requests per minute limit (default: 60)
- `--model`: VLM model (default: `openai/gpt-4o`)
- `--base-url`: API base URL (default: `https://openrouter.ai/api/v1`)
- `--api-key`: API key (overrides env var)
- `--batch-size`: Batch size for processing (default: 100)

**Example:**

```bash
# Detect objects in images using VLM
uv run python -m obh.detect vlm \
  --input images/ \
  --output detections.jsonl \
  --rpm 30 \
  --batch-size 50
```

**Output Format:**
Each line in the JSONL file is a JSON object with:
- `objects`: Object with `labels` (array of object names) and `bbox` (array of bounding boxes as [x_min, y_min, x_max, y_max])
- `file_path`: Path to the processed image file

**Processing Details:**
- Recursively finds image files in the input directory
- Uses multi-threaded batch processing for efficient detection
- Displays progress bars for each batch
- Validates responses and handles errors gracefully
- Prints a summary of attempted, successful, and failed detections at the end

## Development

### Code Style
- Use `uv run ruff check --fix .` to lint and format code.
- Run `uv run pytest` for tests (add tests under `tests/`).

### Project Structure
- `obh/`: Main package
  - `generate.py`: CLI entry point for generation tasks
  - `detect.py`: CLI entry point for detection tasks
  - `utils/`: Shared utilities
    - `llm_utils.py`: LLM-related helper functions
    - `validation.py`: Response validation functions
- `tests/`: Unit tests

## Contributing

Follow the guidelines in `AGENTS.md` for code style, testing, and PR workflow.